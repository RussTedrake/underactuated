{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00001-142a6d01-32b5-4a15-aa12-c164d4e5d662",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1908,
    "execution_start": 1644458971739,
    "id": "A4QOaw_zYLfI",
    "output_cleared": true,
    "source_hash": "e27e2233"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib import cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00003-e23464ff-88d3-4b47-958a-88c8f84dfc52",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "# The Grid World\n",
    "\n",
    "We have seen in class that we can obtain value function using [FittedValueIteration](https://deepnote.com/project/Ch-7-Dynamic-Programming-Um_5m_ESQkebC8UvD4jWzg/%2Fdp.ipynb). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00005-ed008a8e-b6be-4b57-9498-f0010fb963ab",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## Linear Programming for Dynamic Programming\n",
    "\n",
    "For our discrete grid world, let's try to obtain the optimal cost-to-go using [linear programming](https://underactuated.csail.mit.edu/dp.html#LP). Linear Programming is an optimization program with linear objective functions as well as linear equality and inequality constraints. If you are not familiar with optimization, you could take a look at the linear programming [tutorial](https://github.com/RobotLocomotion/drake/blob/master/tutorials/linear_program.ipynb) in Drake. The following cells are setting up the grid world and the transition matrix $T$ in eq(14) in the textbook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00005-79c1e127-c5b6-44d4-835e-2c37185161db",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 102,
    "execution_start": 1644439714617,
    "output_cleared": true,
    "source_hash": "ad8aa506"
   },
   "outputs": [],
   "source": [
    "xbins = range(0, 21)\n",
    "ybins = range(0, 21)\n",
    "[X, Y] = np.meshgrid(xbins, ybins)\n",
    "states = np.vstack((X.reshape(441), Y.reshape(441)))\n",
    "\n",
    "[ux, uy] = np.meshgrid([-1, 0, 1], [-1, 0, 1])\n",
    "inputs = np.vstack((ux.reshape(9), uy.reshape(9)))\n",
    "\n",
    "goal = [2, 8]\n",
    "\n",
    "\n",
    "def obstacle(x):\n",
    "    return x[0] >= 6 and x[0] <= 8 and x[1] >= 4 and x[1] <= 7\n",
    "\n",
    "\n",
    "A = np.eye(2)\n",
    "B = np.eye(2)\n",
    "\n",
    "input_dim = inputs.shape[1]\n",
    "state_dim = states.shape[1]\n",
    "\n",
    "T = np.zeros([state_dim, state_dim, input_dim])\n",
    "\n",
    "for i in range(input_dim):\n",
    "    for j in range(state_dim):\n",
    "        next_state = A @ states[:, j] + B @ inputs[:, i]\n",
    "        ind = np.argmin(np.linalg.norm(states.T - next_state, axis=1))\n",
    "        T[j, ind, i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00006-e49c4511-a352-4c6d-b9d3-15ed353abc97",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 5,
    "execution_start": 1644439716636,
    "output_cleared": true,
    "source_hash": "13e753a6"
   },
   "outputs": [],
   "source": [
    "def min_time_cost(x, u):\n",
    "    state_cost = 1\n",
    "    if obstacle(x):\n",
    "        state_cost = 10\n",
    "    if np.array_equal(x, goal):\n",
    "        state_cost = 0\n",
    "    action_cost = np.linalg.norm(u, 1)\n",
    "    if action_cost > 1:\n",
    "        action_cost = 10\n",
    "    return state_cost + action_cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00007-d331d889-3006-43c0-a820-8984ec5585a1",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "Now it's your turn to code up the linear program for solving the optimal cost-to-go. These Drake [tutorials](https://github.com/RobotLocomotion/drake/tree/master/tutorials) could be super helpful for setting up the optimization program. To deal with numerical instability, you should use a discount factor $\\gamma$ for the Bellman update: $$ J \\leq l(a) + \\gamma T(a) J, \\quad \\forall a.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00008-e1c62275-3cdf-4482-bf3d-91d12da5737f",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": true,
    "output_cleared": true,
    "source_hash": "b972adf3"
   },
   "outputs": [],
   "source": [
    "from pydrake.solvers import MathematicalProgram, Solve\n",
    "import numpy as np\n",
    "\n",
    "# Create an empty MathematicalProgram named prog (with no decision variables,\n",
    "# constraints or costs)\n",
    "prog = MathematicalProgram()\n",
    "J = prog.NewContinuousVariables(state_dim, \"J\")\n",
    "\n",
    "gamma = 0.99999\n",
    "\n",
    "for i in range(input_dim):\n",
    "    l = np.zeros(state_dim)\n",
    "    for j in range(state_dim):\n",
    "        ## Calculate\n",
    "        l[j] = 0  # modify here\n",
    "        ## Modify here\n",
    "        ## Add Constraint for each entry of J\n",
    "\n",
    "\n",
    "## Modify here\n",
    "## Add cost to prog\n",
    "\n",
    "\n",
    "result = Solve(prog)\n",
    "J_value = np.reshape(result.GetSolution(J), X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00010-de467e71-3ce0-4256-a888-b49a5603b84f",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "Let's visualize the value function you calculated using LP. It should be similiar to the plot obtained from FittedValueIteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00011-2ab52873-bb28-46fa-8dcc-80826da81f71",
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     280
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 195,
    "execution_start": 1644439733628,
    "output_cleared": true,
    "source_hash": "53bd7a35"
   },
   "outputs": [],
   "source": [
    "(fig, ax) = plt.subplots()\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"y\")\n",
    "ax.set_title(\"Cost-to-Go\")\n",
    "k = ax.imshow(J_value, cmap=cm.jet)\n",
    "ax.invert_yaxis()\n",
    "plt.colorbar(k)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00012-36305c01-3e51-4723-8be0-f3fc9728f140",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## Autograding\n",
    "You can check your work by running the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00013-f5299738-e0e5-4ec8-9b8a-c4cb6ecdd304",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1000,
    "execution_start": 1644439736206,
    "output_cleared": true,
    "source_hash": "8427ffb4"
   },
   "outputs": [],
   "source": [
    "from underactuated.exercises.dp.test_lp_dp import Testlpdp\n",
    "from underactuated.exercises.grader import Grader\n",
    "\n",
    "Grader.grade_output([Testlpdp], [locals()], \"results.json\")\n",
    "Grader.print_test_results(\"results.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00014-3bf31a41-9058-40e9-b82f-959f8ef2ff0c",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": true,
    "output_cleared": true,
    "source_hash": "b623e53d"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=3fa5d65c-ca55-4511-a03a-c050ee92f204' target=\"_blank\">\n",
    "<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n",
    "Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "colab": {
   "collapsed_sections": [],
   "name": "Underactuated Robotics - The Simple Pendulum.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "46806028-42c2-4d13-b71d-1e032cd929de",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}