{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": "29c0b32d-103d-4e74-859d-faa3069c030e",
    "deepnote_cell_height": 819,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1502,
    "execution_start": 1645649041919,
    "source_hash": "2a6db6d4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import mpld3\n",
    "import numpy as np\n",
    "import pydot\n",
    "from IPython.display import HTML, SVG, Latex, display\n",
    "from pydrake.all import (AddMultibodyPlantSceneGraph, ConstantVectorSource,\n",
    "                         DiagramBuilder, BasicVector,\n",
    "                         LinearQuadraticRegulator,\n",
    "                         MultilayerPerceptron,\n",
    "                         PerceptronActivationType,\n",
    "                         MeshcatVisualizerCpp, MultibodyPlant, Parser,RandomGenerator,\n",
    "                         Saturation, SceneGraph, Simulator, StartMeshcat,\n",
    "                         WrapToSystem, VectorSystem, LeafSystem)\n",
    "from pydrake.all import (DiagramBuilder, DiscreteAlgebraicRiccatiEquation,\n",
    "                         DynamicProgrammingOptions, FittedValueIteration,\n",
    "                         InputPortIndex, LeafSystem, LinearSystem,\n",
    "                         MeshcatVisualizerCpp, MultilayerPerceptron,\n",
    "                         PerceptronActivationType, PeriodicBoundaryCondition,\n",
    "                         RandomGenerator, Rgba, RigidTransform, RotationMatrix,\n",
    "                         SceneGraph, Simulator, StartMeshcat, WrapToSystem,\n",
    "                         ZeroOrderHold)\n",
    "from scipy.linalg import block_diag\n",
    "from IPython.display import HTML, clear_output, display\n",
    "\n",
    "from pydrake.common.containers import namedview\n",
    "from pydrake.solvers.mathematicalprogram import MathematicalProgram, Solve\n",
    "\n",
    "from underactuated import FindResource, running_as_notebook\n",
    "from underactuated.optimizers import Adam\n",
    "\n",
    "from underactuated.meshcat_cpp_utils import MeshcatSliders\n",
    "from underactuated.pendulum import PendulumVisualizer\n",
    "from pydrake.examples.pendulum import PendulumGeometry, PendulumPlant\n",
    "\n",
    "\n",
    "if running_as_notebook:\n",
    "    mpld3.enable_notebook()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": "0e3b6237-73ad-4e80-b490-4e3083c523c0",
    "deepnote_cell_height": 130.1875,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 8,
    "execution_start": 1645649043434,
    "source_hash": "a20aae47",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meshcat is now available at http://localhost:7000\n"
     ]
    }
   ],
   "source": [
    "# Start the visualizer (run this cell only once, each instance consumes a port)\n",
    "meshcat = StartMeshcat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "1fbb2759-f507-46f8-8b28-16a7466a9a83",
    "deepnote_cell_height": 82,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "# Let's load up our Penulum from Drake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": "f435aedc-9b62-4d7b-a846-17dd89500f8a",
    "deepnote_cell_height": 405,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 0,
    "execution_start": 1645649043485,
    "source_hash": "3049175e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "plant = PendulumPlant()\n",
    "plant_context = plant.CreateDefaultContext()\n",
    "simulator = Simulator(plant)\n",
    "actuation_input_port_index = 0\n",
    "num_states = plant.num_continuous_states()\n",
    "num_inputs = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we'll set up our training data for the problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": "6edd5be0-f898-4b92-8c3f-28cac01b60fe",
    "deepnote_cell_height": 603,
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     21.1875
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 2,
    "execution_start": 1645649495335,
    "source_hash": "26afb723",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set up training data. states are (theta, theta_dot)\n",
    "time_step = 0.01\n",
    "num_samples = 50\n",
    "\n",
    "theta_states = np.linspace(0,2*np.pi, num_samples)\n",
    "theta_dot_states = np.linspace(-10,10, num_samples)\n",
    "\n",
    "state_grid = np.meshgrid(theta_states, theta_dot_states, indexing = 'ij')\n",
    "state_data = np.vstack([s.flatten() for s in state_grid])\n",
    "\n",
    "# zero cost state\n",
    "# zero_cost_state = np.array([0, np.pi, 0, 0])\n",
    "target_state = np.array([np.pi,0.]).reshape(-1,1)\n",
    "state_data = np.hstack([state_data, target_state])\n",
    "\n",
    "num_state_data = state_data.shape[1]\n",
    "cur_state = plant_context.get_mutable_continuous_state_vector()\n",
    "\n",
    "state_dynamics_x = np.empty((num_state_data, num_states))\n",
    "\n",
    "dstate_dynamics_du = np.empty((num_states, num_inputs, num_state_data))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to be able to compute the quadratic state cost. Implement the function compute_quadratic_cost which should be able to take in a (num_state x num_samples) size data vector and output $x^TQx$ for each $x$ in the data vector. We also will want to be able to compute this same function with respect to some fixed target state. Implement compute_state_cost which computes $(x-\\text{target\\_state})^TQ(x-\\text{target\\_state})$ for each vector in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_quadratic_cost(Q, data):\n",
    "    # computes the cost of each sample data\n",
    "    # Q is of size (num_states x num_states)\n",
    "    # data is of size (num_states x num_samples)\n",
    "    # return a cost of size (num_samples,)\n",
    "    assert Q.shape[0] == data.shape[0]\n",
    "    if len(data.shape) != 2:\n",
    "        data=data.reshape(-1,1)\n",
    "    cost = np.zeros(data.shape[1]) # MODIFY HERE \n",
    "    return cost\n",
    "\n",
    "def compute_state_cost(Q, target_state, data):\n",
    "    # compute the state cost of each sample in state\n",
    "    # Q is of size (num_states x num_states)\n",
    "    # target_state is of size (num_states x 1)\n",
    "    # state is of size (num_states x num_samples)\n",
    "    # return is of size (num_samples,)\n",
    "    if len(data.shape) != 2:\n",
    "        data=data.reshape(-1,1)\n",
    "    return np.zeros(data.shape[1])# MODIFY HERE  \n",
    "\n",
    "# Do not modify\n",
    "Q = np.diag([20, 2])\n",
    "R_diag = np.array([2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "87d9726c-8af8-4ca0-9c1a-4572ebf32102",
    "deepnote_cell_height": 142.78125,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "# Computing the optimal input\n",
    "\n",
    "Recall that given a control affine system, and positive definite quadratic penalty on the inputs, we can compute the optimal input with respect to our value function. Implement the optimal control given $f_2(x) = \\frac{\\partial x}{\\partial u}$ and $\\frac{\\partial J}{\\partial x}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_u_star(R_diag, dJdX, dstate_dynamics_du):\n",
    "    # R_diag is an array of size num_inputs that is the diagonal entries of R \n",
    "    # dJdX is of shape (num_states x num_samples) \n",
    "    # dstate_dynamics_du are (num_states x num_inputs x num_samples)\n",
    "    # return u_star of shape (num_inputs x num_samples)\n",
    "    \n",
    "    return np.zeros((dstate_dynamics_du.shape[1], dstate_dynamics_du.shape[2])) # MODIFY HERE\n",
    "\n",
    "\n",
    "\n",
    "dJdX = np.asfortranarray(np.random.randn(num_states, num_state_data))\n",
    "dstate_dynamics_du = np.random.randn(num_states, num_inputs, num_state_data)\n",
    "u_star = compute_u_star(R_diag, dJdX, dstate_dynamics_du)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "5f9b093b-733a-4b34-978d-e1f696507029",
    "deepnote_cell_height": 165.171875,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "# Set up Multilayer perceptron\n",
    "Drake has an implementation of the multilayer perceptron (a.ka. fully connected neural network) Here we set up a MLP with four inputs, 2 hidden layers with ReLU activation, and one output. We also set up an optimizer for changing the weights of our neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cell_id": "9b6b6033-7454-4f6c-9d12-c913691396fa",
    "deepnote_cell_height": 279,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 0,
    "execution_start": 1645650780245,
    "source_hash": "db42e6f9",
    "tags": []
   },
   "outputs": [],
   "source": [
    "value_mlp = MultilayerPerceptron(\n",
    "        #whether to send input i to cos(x_i), sin(x_i)\n",
    "        [True, False],\n",
    "        [128,128,1],\n",
    "        [PerceptronActivationType.kReLU, \n",
    "         PerceptronActivationType.kReLU,\n",
    "        #  PerceptronActivationType.kReLU,\n",
    "         PerceptronActivationType.kIdentity])\n",
    "# MLP is a drake system and therefore has state (the current weights). We initialize this state randomly\n",
    "value_mlp_context = value_mlp.CreateDefaultContext()\n",
    "generator = RandomGenerator(152)\n",
    "value_mlp.SetRandomContext(value_mlp_context, generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "26866f8c-5660-43ae-bb96-d943db2220a1",
    "deepnote_cell_height": 52.390625,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "We'll print out the shapes of our layers. Make sure you understand why these layers have these shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cell_id": "78c21fce-9861-44f1-845d-0e9b02b6b2e7",
    "deepnote_cell_height": 188.5625,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 14,
    "execution_start": 1645650782282,
    "source_hash": "f4c8fc64",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 3)\n",
      "(128, 128)\n",
      "(1, 128)\n"
     ]
    }
   ],
   "source": [
    "print(value_mlp.GetWeights(value_mlp_context,0).shape)\n",
    "print(value_mlp.GetWeights(value_mlp_context,1).shape)\n",
    "print(value_mlp.GetWeights(value_mlp_context,2).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "99c976bf-0b79-4a39-b9b0-fc72eaa8f8d7",
    "deepnote_cell_height": 82,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "# Fitted Value Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ContinuousFittedValueIteration(plant,\n",
    "                                   plant_context,\n",
    "                                   value_mlp,\n",
    "                                   state_cost_function,\n",
    "                                   compute_u_star,\n",
    "                                   R_diag,\n",
    "                                   state_samples,\n",
    "                                   time_step=0.01,\n",
    "                                   discount_factor=1.0,\n",
    "                                   input_port_index=0,\n",
    "                                   lr=0.001,\n",
    "                                   minibatch=None,\n",
    "                                   epochs=1000,\n",
    "                                   optim_steps_per_epoch=25,\n",
    "                                   input_limits=None,\n",
    "                                   target_state = None):\n",
    "    input_port = plant.get_input_port(input_port_index)\n",
    "    num_states = plant.num_continuous_states()\n",
    "    num_inputs = input_port.size()\n",
    "    if target_state is not None:\n",
    "        np.append(state_samples,target_state)\n",
    "\n",
    "    N = state_samples.shape[1]\n",
    "\n",
    "    # perform some checks to make sure the inputs to the function make sense\n",
    "    assert plant_context.has_only_continuous_state()\n",
    "    assert value_mlp.get_input_port().size() == num_states\n",
    "    assert value_mlp.layers()[-1] == 1\n",
    "    assert R_diag.shape == (num_inputs,)\n",
    "    assert state_samples.shape[0] == num_states\n",
    "    assert time_step > 0.0\n",
    "    assert discount_factor > 0.0 and discount_factor <= 1.0\n",
    "    if input_limits is not None:\n",
    "        assert num_inputs == 1, \"Input limits are only supported for scalar inputs (for now)\"\n",
    "        assert len(input_limits) == 2\n",
    "\n",
    "\n",
    "    # random initialization of our Neural Network weights\n",
    "    mlp_context = value_mlp.CreateDefaultContext()\n",
    "    generator = RandomGenerator(123)\n",
    "    value_mlp.SetRandomContext(mlp_context, generator)\n",
    "\n",
    "    state_cost = state_cost_function(state_samples)\n",
    "    state_dynamics_x = np.empty((N, num_states))\n",
    "    dstate_dynamics_du = np.empty((num_states, num_inputs, N))\n",
    "    Rinv = 1/R_diag\n",
    "    state = plant_context.get_mutable_continuous_state_vector()\n",
    "\n",
    "\n",
    "    # Precompute dynamics of zero-order hold and cost.\n",
    "    for i in range(N):\n",
    "        u = np.zeros(num_inputs)\n",
    "        input_port.FixValue(plant_context, u)\n",
    "        state.SetFromVector(state_samples[:, i])\n",
    "        state_dynamics_x[i] = plant.EvalTimeDerivatives(\n",
    "            plant_context).CopyToVector()\n",
    "        for j in range(num_inputs):\n",
    "            u[j] = 1\n",
    "            input_port.FixValue(plant_context, u)\n",
    "            dstate_dynamics_du[:, j, i] = plant.EvalTimeDerivatives(\n",
    "                plant_context).CopyToVector() - state_dynamics_x[i]\n",
    "            u[j] = 0\n",
    "\n",
    "\n",
    "    optimizer = Adam(value_mlp.GetMutableParameters(mlp_context), lr=lr)\n",
    "\n",
    "    if minibatch and target_state is not None:\n",
    "        M = minibatch + 1\n",
    "    elif minibatch:\n",
    "        M = minibatch\n",
    "    else:\n",
    "        M = N\n",
    "\n",
    "    J = np.zeros((1,M))\n",
    "    Jnext = np.zeros((1,M))\n",
    "    Jd = np.zeros((1,M))\n",
    "    dJdX = np.asfortranarray(np.zeros((num_states, M)))\n",
    "    dloss_dparams = np.zeros(value_mlp.num_parameters())\n",
    "\n",
    "    last_loss = np.inf\n",
    "    for epoch in range(epochs if running_as_notebook else 2):\n",
    "        if minibatch:\n",
    "            batch = np.random.randint(0, N, minibatch)\n",
    "            #always include the target state in the batch\n",
    "            if target_state is not None:\n",
    "                batch = np.append(batch, -1)\n",
    "        else:\n",
    "            batch = range(N)\n",
    "        \n",
    "        # Compute dJdX\n",
    "        value_mlp.BatchOutput(mlp_context, state_samples[:,batch], J, dJdX)\n",
    "\n",
    "        # compute the next input\n",
    "        u_star = np.zeros((dstate_dynamics_du[:, :, batch].shape[1], dstate_dynamics_du[:, :, batch].shape[2]))#MODIFY HERE\n",
    "\n",
    "        #clamp to input limits\n",
    "        if input_limits is not None:\n",
    "            u_star = np.clip(u_star, input_limits[0], input_limits[1])\n",
    "\n",
    "        # compute Xnext\n",
    "        Xnext = np.zeros_like(state_samples[:,batch]) #MODIFY HERE \n",
    "        \n",
    "        # compute cost\n",
    "        G = np.zeros(len(batch)) #MODIFY HERE\n",
    "\n",
    "\n",
    "        value_mlp.BatchOutput(mlp_context, Xnext, Jnext)\n",
    "\n",
    "        # Create the target network\n",
    "        Jd[:] = np.zeros(len(batch)) #MODIFY HERE\n",
    "\n",
    "        for i in range(optim_steps_per_epoch if running_as_notebook else 2):\n",
    "            # low pass filter target network\n",
    "            if (i+1) % 50:\n",
    "                alpha = 5e-4\n",
    "                Jd[:] = (1-alpha)*Jd[:] + alpha*Jnext[:]\n",
    "            \n",
    "            # This does back prop\n",
    "            loss = value_mlp.BackpropagationMeanSquaredError(\n",
    "                mlp_context, state_samples[:,batch], Jd, dloss_dparams)\n",
    "            optimizer.step(loss, dloss_dparams)\n",
    "        if not minibatch and np.linalg.norm(last_loss - loss) < 1e-8:\n",
    "            break\n",
    "        last_loss = loss\n",
    "        if epoch % 20 == 0:\n",
    "            clear_output(wait=True)\n",
    "        print(f\"epoch {epoch}: loss = {loss}\")\n",
    "\n",
    "    return mlp_context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train our network!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "cell_id": "53ea0488-8292-48be-8f28-771b52666ed4",
    "deepnote_cell_height": 1007,
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     328.1875,
     328.1875,
     328.1875
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 68150,
    "execution_start": 1645650846751,
    "source_hash": "30639e54",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "state_cost_function = partial(compute_state_cost, Q, target_state)\n",
    "\n",
    "\n",
    "#cartpole CVI\n",
    "value_mlp_context = ContinuousFittedValueIteration(plant,\n",
    "                                   plant_context,\n",
    "                                   value_mlp,\n",
    "                                   state_cost_function,\n",
    "                                   compute_u_star,\n",
    "                                   R_diag,\n",
    "                                   state_data,\n",
    "                                   time_step=time_step,\n",
    "                                   discount_factor=0.999,\n",
    "                                   input_port_index=0,\n",
    "                                   lr=1e-4,\n",
    "                                   minibatch=64,\n",
    "                                   epochs=300,\n",
    "                                   optim_steps_per_epoch=100,\n",
    "                                   input_limits=[-2,2],\n",
    "                                   target_state = None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "cell_id": "30c2b5a4-3a04-4676-a35d-5f1c9c61d439",
    "deepnote_cell_height": 531,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 21,
    "execution_start": 1645650916453,
    "source_hash": "150be29f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ContinuousFittedValueIterationPolicyComputeUStar(LeafSystem):\n",
    "    def __init__(self,\n",
    "                 plant,\n",
    "                 value_mlp,\n",
    "                 value_mlp_context,\n",
    "                 R_diag,\n",
    "                 compute_u_star,\n",
    "                 input_port_index=0,\n",
    "                 input_limits=None):\n",
    "        LeafSystem.__init__(self)\n",
    "\n",
    "        self.num_plant_states = value_mlp.get_input_port().size()\n",
    "        self._plant = plant\n",
    "        self._plant_context = plant.CreateDefaultContext()\n",
    "\n",
    "        self.value_mlp = value_mlp\n",
    "        self.value_mlp_context = value_mlp_context\n",
    "        self.J = np.zeros((1,1))\n",
    "        self.dJdX = np.asfortranarray(np.zeros((self.num_plant_states, 1)))\n",
    "\n",
    "        self.compute_u_star = compute_u_star\n",
    "\n",
    "        self.Rinv = 1/R_diag\n",
    "        self.R_diag = R_diag\n",
    "        self.input_limits = input_limits\n",
    "        self.DeclareVectorInputPort(\"plant_state\", self.num_plant_states)\n",
    "        self._plant_input_port = self._plant.get_input_port(input_port_index)\n",
    "        self.DeclareVectorOutputPort(\"output\", self._plant_input_port.size(),\n",
    "                                     self.CalcOutput)\n",
    "\n",
    "    def CalcOutput(self, context, output):\n",
    "        num_inputs = self._plant_input_port.size()\n",
    "        u = np.zeros(num_inputs)\n",
    "        plant_state = self.get_input_port().Eval(context)\n",
    "\n",
    "        self.value_mlp.BatchOutput(self.value_mlp_context,\n",
    "                                   np.atleast_2d(plant_state).T, self.J,\n",
    "                                   self.dJdX)\n",
    "\n",
    "        self._plant_context.SetContinuousState(plant_state)\n",
    "        self._plant_input_port.FixValue(self._plant_context, u)\n",
    "        state_dynamics_x = self._plant.EvalTimeDerivatives(\n",
    "            self._plant_context).CopyToVector()\n",
    "\n",
    "\n",
    "        dstate_dynamics_du = np.empty((self.num_plant_states, num_inputs, 1))\n",
    "        u_star_russ = np.empty(num_inputs)\n",
    "        for i in range(num_inputs):\n",
    "            u[i] = 1\n",
    "            self._plant_input_port.FixValue(self._plant_context, u)\n",
    "            dstate_dynamics_du[:,:,i] = (self._plant.EvalTimeDerivatives(\n",
    "                self._plant_context).CopyToVector() - state_dynamics_x).reshape(-1,1)\n",
    "            if self.input_limits != None:\n",
    "                ui = np.minimum(np.maximum(ui, self.input_limits[0]),\n",
    "                                self.input_limits[1])\n",
    "            u[i] = 0\n",
    "\n",
    "        u_star = self.compute_u_star(self.R_diag,  self.dJdX, dstate_dynamics_du)[:,0]\n",
    "        if self.input_limits is not None:\n",
    "            u_star = np.clip(u_star,self.input_limits[0], self.input_limits[1])\n",
    "        for i in range(num_inputs):\n",
    "            output.SetAtIndex(i, u_star[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "6adcc73c-f8fe-4808-b72c-170b4c26cdba",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "## Lets now build our controller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "cell_id": "985a5c34-2126-4ad1-9206-e30ab776b842",
    "deepnote_cell_height": 405,
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     404.9375,
     155.5
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 14,
    "execution_start": 1645651770904,
    "source_hash": "9eaaaeb1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# initialize controller and plant\n",
    "closed_loop_builder = DiagramBuilder()\n",
    "plant_cl, scene_graph_cl = closed_loop_builder.AddSystem(PendulumPlant()), closed_loop_builder.AddSystem(SceneGraph())\n",
    "\n",
    "controller_sys = ContinuousFittedValueIterationPolicyComputeUStar(plant_cl, value_mlp, value_mlp_context, R_diag, compute_u_star)\n",
    "\n",
    "PendulumGeometry.AddToBuilder(closed_loop_builder, plant_cl.get_state_output_port(),\n",
    "                                  scene_graph_cl)\n",
    "\n",
    "controller = closed_loop_builder.AddSystem(controller_sys)\n",
    "# we assume a zero-order hold between time steps\n",
    "zoh = closed_loop_builder.AddSystem(ZeroOrderHold(time_step,1))\n",
    "\n",
    "# wire all the systems together\n",
    "closed_loop_builder.Connect(plant_cl.get_output_port(), controller.get_input_port())\n",
    "closed_loop_builder.Connect(controller.get_output_port(), zoh.get_input_port())\n",
    "closed_loop_builder.Connect(zoh.get_output_port(), plant_cl.get_input_port())\n",
    "\n",
    "meshcat.Delete()\n",
    "meshcat.Set2dRenderMode(X_WC = RigidTransform(RotationMatrix.MakeZRotation(np.pi), [0,1,0]))\n",
    "vis = MeshcatVisualizerCpp.AddToBuilder(closed_loop_builder, scene_graph_cl, meshcat)\n",
    "\n",
    "diagram_closed_loop = closed_loop_builder.Build()\n",
    "\n",
    "simulator = Simulator(diagram_closed_loop)\n",
    "simulator_context = simulator.get_mutable_context()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "cell_id": "a0b26af6-a3ac-4fbc-993b-982c88803bb0",
    "deepnote_cell_height": 244.1875,
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     21.1875
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 25390,
    "execution_start": 1645652252169,
    "source_hash": "b233975c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "simulator.set_target_realtime_rate(1.0 if running_as_notebook else 0.0)\n",
    "num_sim = 5\n",
    "for i in range(num_sim):\n",
    "    duration = 5.0 if running_as_notebook else 0.1\n",
    "    simulator_context.SetTime(0.)\n",
    "    simulator_context.SetContinuousState(np.array([2*np.pi*np.random.rand(), 0]))\n",
    "    simulator.Initialize()\n",
    "    simulator.AdvanceTo(duration)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "cell_id": "4389a26b-046b-4afc-b502-988971eb35f9",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 100018,
    "execution_start": 1645653206845,
    "source_hash": "d0914cf3",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total score is 10/10.\n",
      "\n",
      "Score for Test compute u_star is 2/2.\n",
      "\n",
      "Score for Test policy is 6/6.\n",
      "\n",
      "Score for Test compute state cost is 2/2.\n"
     ]
    }
   ],
   "source": [
    "from underactuated.exercises.dp.pendulum_cvi.test_pendulum_cvi import TestFittedCartpole\n",
    "from underactuated.exercises.grader import Grader\n",
    "Grader.grade_output([TestFittedCartpole], [locals()], 'results.json')\n",
    "Grader.print_test_results('results.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "4c28395d-e1af-43fb-8bb7-396c35dbb270",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "## Here you can try to tune parameters to get the Cartpole to swing up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The notebook is not graded after this point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "cell_id": "e8593e95-36d3-4fb6-8886-81ff2e20c1ee",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": true,
    "execution_millis": 1,
    "execution_start": 1645635374379,
    "source_hash": "caa70e6d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load_cartpole()\n",
    "builder = DiagramBuilder()\n",
    "cart_plant, cart_scene_graph = AddMultibodyPlantSceneGraph(builder, time_step=0.0)\n",
    "file_name = FindResource(\"models/cartpole.urdf\")\n",
    "Parser(cart_plant).AddModelFromFile(file_name)\n",
    "cart_plant.Finalize()\n",
    "cart_plant_context = cart_plant.CreateDefaultContext()\n",
    "\n",
    "cart_diagram = builder.Build()\n",
    "\n",
    "num_states = cart_plant.num_continuous_states()\n",
    "\n",
    "\n",
    "cart_actuation_port_index = 3\n",
    "num_inputs = cart_plant.get_input_port(cart_actuation_port_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "cell_id": "d7ff07f0-dcad-40f7-877f-dced8e8183cc",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": true,
    "execution_millis": 170,
    "execution_start": 1645634547647,
    "source_hash": "5db1dcfb",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set up training data. states are (x, theta, x_dot, theta_dot)\n",
    "num_samples = 3\n",
    "x_states_cart = np.linspace(-2,2,num_samples)\n",
    "theta_states_cart = np.linspace(0, 2*np.pi, 50)\n",
    "x_dot_states_cart = np.linspace(-10, 10,num_samples)\n",
    "theta_dot_states_cart = np.linspace(-10,10,num_samples)\n",
    "state_grid_cart = np.meshgrid(x_states_cart, theta_states_cart, x_dot_states_cart, theta_dot_states_cart, indexing = 'ij')\n",
    "state_data_cart = np.vstack([s.flatten() for s in state_grid_cart])\n",
    "\n",
    "# zero cost state\n",
    "cart_target_state = np.array([0, np.pi, 0, 0]).reshape(-1,1)\n",
    "\n",
    "Q_cart = np.diag([0.1, 20, 1, 1])\n",
    "R_cart = np.array([2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "cell_id": "b95044ba-eb75-4a95-88c7-a484b88f5527",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": true,
    "execution_millis": 2,
    "execution_start": 1645634553127,
    "source_hash": "8eb1004f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "cart_value_mlp = MultilayerPerceptron(\n",
    "        # [num_states,16,32,16,1],\n",
    "        [False, True, False, False],\n",
    "        [128,128,1],\n",
    "        [PerceptronActivationType.kReLU, \n",
    "         PerceptronActivationType.kReLU,\n",
    "        #  PerceptronActivationType.kReLU,\n",
    "         PerceptronActivationType.kIdentity])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "cell_id": "7f64db43-b67f-4dfd-b398-0c8376b26a1a",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": true,
    "execution_millis": 1761008,
    "execution_start": 1645636184226,
    "source_hash": "736824f3",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: loss = 0.16206193143533398\n",
      "epoch 1: loss = 0.17163984529174994\n"
     ]
    }
   ],
   "source": [
    "state_cost_function_cart = partial(compute_state_cost, Q_cart, cart_target_state)\n",
    "cart_value_mlp_context = ContinuousFittedValueIteration(cart_plant,\n",
    "                                   cart_plant_context,\n",
    "                                   cart_value_mlp,\n",
    "                                   state_cost_function_cart,\n",
    "                                   compute_u_star,\n",
    "                                   R_cart,\n",
    "                                   state_data_cart,\n",
    "                                   time_step=0.01,\n",
    "                                   discount_factor=0.9999,\n",
    "                                   input_port_index=cart_actuation_port_index,\n",
    "                                   lr=1e-4,\n",
    "                                   minibatch=64,\n",
    "                                   epochs=2,\n",
    "                                   optim_steps_per_epoch=100,\n",
    "                                   input_limits=None,\n",
    "                                   target_state = target_state)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "cell_id": "0b6402b0-9b3f-4b14-91b7-07d9f6b5bd48",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": true,
    "execution_millis": 0,
    "execution_start": 1645638861629,
    "source_hash": "64d418b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# initialize controller and plant\n",
    "closed_loop_builder_cart = DiagramBuilder()\n",
    "\n",
    "cart_plant_cl, cart_scene_graph_cl = AddMultibodyPlantSceneGraph(closed_loop_builder_cart, time_step=0.0)\n",
    "\n",
    "file_name = FindResource(\"models/cartpole.urdf\")\n",
    "Parser(cart_plant_cl).AddModelFromFile(file_name)\n",
    "cart_plant_cl.Finalize()\n",
    "cart_plant_context_cl = cart_plant_cl.CreateDefaultContext()\n",
    "cart_controller_sys = ContinuousFittedValueIterationPolicyComputeUStar(cart_plant_cl, cart_value_mlp, cart_value_mlp_context, R_diag, compute_u_star, input_port_index = cart_actuation_port_index)\n",
    "\n",
    "\n",
    "cart_controller = closed_loop_builder_cart.AddSystem(cart_controller_sys)\n",
    "# we assume a zero-order hold between time steps\n",
    "zoh_cart = closed_loop_builder_cart.AddSystem(ZeroOrderHold(time_step,1))\n",
    "\n",
    "# wire all the systems together\n",
    "closed_loop_builder_cart.Connect(cart_plant_cl.get_state_output_port(), cart_controller.get_input_port())\n",
    "closed_loop_builder_cart.Connect(cart_controller.get_output_port(), zoh_cart.get_input_port())\n",
    "closed_loop_builder_cart.Connect(zoh_cart.get_output_port(), cart_plant_cl.get_input_port(cart_actuation_port_index))\n",
    "\n",
    "meshcat.Delete()\n",
    "meshcat.Set2dRenderMode(xmin=-2.5, xmax=2.5, ymin=-1.0, ymax=2.5)\n",
    "vis = MeshcatVisualizerCpp.AddToBuilder(closed_loop_builder_cart, cart_scene_graph_cl, meshcat)\n",
    "\n",
    "cart_diagram_closed_loop = closed_loop_builder_cart.Build()\n",
    "\n",
    "cart_simulator = Simulator(cart_diagram_closed_loop)\n",
    "cart_simulator_context = cart_simulator.get_mutable_context()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "cell_id": "75403dbf-8105-40db-9036-e6cc375142fc",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": true,
    "execution_millis": 9978,
    "execution_start": 1645638876892,
    "source_hash": "37af6691",
    "tags": []
   },
   "outputs": [],
   "source": [
    "cart_simulator.set_target_realtime_rate(1.0 if running_as_notebook else 0.0)\n",
    "duration = 10.0 if running_as_notebook else 0.1\n",
    "for i in range(1):\n",
    "    cart_simulator_context.SetTime(0.)\n",
    "    cart_simulator_context.SetContinuousState([0, 0, 0, 0])\n",
    "    cart_simulator.Initialize()\n",
    "    cart_simulator.AdvanceTo(duration)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "deepnote": {
   "is_reactive": false
  },
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "b2f3145b-4c0a-46f8-bab8-ece5bf99374d",
  "interpreter": {
   "hash": "548969b9428b5e37794aaff26b420f7b13ebbe6162d5687768225889fdf57ab4"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}