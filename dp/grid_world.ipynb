{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TKvYiJgnYExi"
   },
   "source": [
    "This notebook provides examples to go along with the [textbook](https://underactuated.csail.mit.edu/dp.html).  I recommend having both windows open, side-by-side!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A4QOaw_zYLfI"
   },
   "outputs": [],
   "source": [
    "import matplotlib.animation as animation\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.display import HTML, display\n",
    "from matplotlib import cm\n",
    "from pydrake.all import (DynamicProgrammingOptions, FittedValueIteration,\n",
    "                         LinearSystem, Simulator)\n",
    "\n",
    "from underactuated import running_as_notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Grid World\n",
    "\n",
    "The setup here is *almost* identical as the simplest version described in the notes.  The only difference is that this agent is allowed to move diagonally in a single step; this is slightly easier to code since I can have two actions (one for left/right, and another for up/down), and write the dynamics as the trivial linear system ${\\bf x}[n+1] = {\\bf u}[n].$  Only the value iteration code needs to know that the states and actions are actually restricted to the integers. I also add a very large cost when the action would be diagonal, so that it is never chosen.\n",
    "\n",
    "The obstacle (pit of despair) is provided by the method below.  Play around with it!  The rest of the code is mostly to support visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_world_example():\n",
    "    time_step = 1\n",
    "    # TODO(russt): Support discrete-time systems in the dynamic programming\n",
    "    # code, and use this properly. For now, just cheat because I know how to\n",
    "    # make the discrete system as a continuous that will be discretized.\n",
    "    plant = LinearSystem(A=np.zeros((2, 2)),\n",
    "                         B=np.eye(2),\n",
    "                         C=np.eye(2),\n",
    "                         D=np.zeros((2, 2)))\n",
    "    simulator = Simulator(plant)\n",
    "    options = DynamicProgrammingOptions()\n",
    "\n",
    "    xbins = range(0, 21)\n",
    "    ybins = range(0, 16)\n",
    "    state_grid = [set(xbins), set(ybins)]\n",
    "\n",
    "    input_grid = [set([-1, 0, 1]), set([-1, 0, 1])]\n",
    "\n",
    "    goal = [2, 8]\n",
    "\n",
    "    def obstacle(x):\n",
    "        return x[0]>=6 and x[0]<=8 and x[1]>=4 and x[1]<=7\n",
    "\n",
    "    [X, Y] = np.meshgrid(xbins, ybins)\n",
    "\n",
    "    frames=[]\n",
    "    def draw(iteration, mesh, cost_to_go, policy):\n",
    "        J = np.reshape(cost_to_go, X.shape)\n",
    "        artists = [ax.imshow(J, cmap=cm.jet)]\n",
    "        artists += [\n",
    "            ax.quiver(X,\n",
    "                      Y,\n",
    "                      np.reshape(policy[0], X.shape),\n",
    "                      np.reshape(policy[1], Y.shape),\n",
    "                      scale=1.4,\n",
    "                      scale_units='x')\n",
    "        ]\n",
    "        frames.append(artists)\n",
    "\n",
    "    if running_as_notebook:\n",
    "        options.visualization_callback = draw\n",
    "\n",
    "    def min_time_cost(context):\n",
    "        x = context.get_continuous_state_vector().CopyToVector()\n",
    "        x = np.round(x)\n",
    "        state_cost = 1\n",
    "        if obstacle(x):\n",
    "            state_cost = 10\n",
    "        if np.array_equal(x, goal):\n",
    "            state_cost = 0\n",
    "        u = plant.get_input_port(0).Eval(context)\n",
    "        action_cost = np.linalg.norm(u, 1)\n",
    "        if action_cost > 1:\n",
    "            action_cost = 10\n",
    "        return state_cost + action_cost\n",
    "\n",
    "    cost_function = min_time_cost\n",
    "    options.convergence_tol = .1;\n",
    "\n",
    "    (fig,ax) = plt.subplots(figsize=(10,6))\n",
    "    ax.set_xlabel(\"x\")\n",
    "    ax.set_ylabel(\"y\")\n",
    "    ax.set_title(\"Cost-to-Go\")\n",
    "\n",
    "    policy, cost_to_go = FittedValueIteration(simulator, cost_function,\n",
    "                                              state_grid, input_grid, time_step,\n",
    "                                              options)\n",
    "\n",
    "    draw('Final', None, cost_to_go, policy.get_output_values())\n",
    "\n",
    "    ax.invert_yaxis()\n",
    "    plt.colorbar(frames[-1][0])\n",
    "\n",
    "    print(\"generating animation...\")\n",
    "    # create animation using the animate() function\n",
    "    ani = animation.ArtistAnimation(fig,\n",
    "                                    frames,\n",
    "                                    interval=200,\n",
    "                                    blit=True,\n",
    "                                    repeat=False)\n",
    "    plt.close('all')\n",
    "\n",
    "    display(HTML(ani.to_jshtml()))\n",
    "\n",
    "grid_world_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your turn.  Change the cost.  Change the obstacles."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Underactuated Robotics - The Simple Pendulum.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
