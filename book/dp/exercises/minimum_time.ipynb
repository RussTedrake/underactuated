{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "c5a8fdbecead4707902db909afb29c82",
    "deepnote_cell_type": "markdown",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Value Iteration for Minimum Time Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "9563b0a6c7c4436dada7024ef741e8a0",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 930,
    "execution_start": 1676517256099,
    "pycharm": {
     "name": "#%%\n"
    },
    "source_hash": "b4b4632f"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from IPython.display import HTML\n",
    "from pydrake.all import (\n",
    "    DiagramBuilder,\n",
    "    DynamicProgrammingOptions,\n",
    "    FittedValueIteration,\n",
    "    LeafSystem,\n",
    "    LinearSystem,\n",
    "    LogVectorOutput,\n",
    "    Simulator,\n",
    ")\n",
    "\n",
    "from underactuated.exercises.dp.minimum_time_utils import (\n",
    "    create_animation,\n",
    "    simulate_and_plot,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "8f0111a2500b43a184427bb846d11921",
    "deepnote_cell_type": "markdown",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Problem Description\n",
    "In this problem you will analyze the performance of the value-iteration algorithm on the minimum-time problem for the double integrator.\n",
    "Don't worry, the value iteration algorithm is provided by Drake, and you won't have to code it!\n",
    "You will be asked to analyze the policy it produces and understand the algorithmic reasons behind the poor performance of the closed loop system.\n",
    "Then you will have to implement on your own the closed-form controller we have studied in class, and compare it with the one obtained numerically.\n",
    "\n",
    "**These are the main steps of the notebook (Items needed to be completed by you are marked as \"TODO\"):**\n",
    "1. Construct the double integrator system.\n",
    "2. Define the objective function for the minimum time problem (TODO).\n",
    "3. Run the value-iteration algorithm.\n",
    "4. Animate the intermediate steps of the algorithm.\n",
    "5. Simulate the double integrator in closed loop with the controller from the value iteration.\n",
    "6. Write down a controller that implements the closed form solution, and test it (TODO)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "a3b739b2834a4609ae4486d3b82e2378",
    "deepnote_cell_type": "markdown",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Dynamics of the Double Integrator\n",
    "We start by writing a function that returns the double-integrator system.\n",
    "We write the dynamics is state-space linear form\n",
    "$$\\dot{\\mathbf{x}} = A \\mathbf{x} + B u,$$\n",
    "where $\\mathbf{x} = [q, \\dot{q}]^T$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "098433a1fe0344feb71af540a8f89f92",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 0,
    "execution_start": 1676517257029,
    "pycharm": {
     "name": "#%%\n"
    },
    "source_hash": "876aa04"
   },
   "outputs": [],
   "source": [
    "# we write a function since we will need to call\n",
    "# this a handful of times\n",
    "\n",
    "\n",
    "def get_double_integrator():\n",
    "    A = np.array([[0, 1], [0, 0]])\n",
    "    B = np.array([[0], [1]])\n",
    "    C = np.eye(2)\n",
    "    D = np.zeros((2, 1))\n",
    "    return LinearSystem(A, B, C, D)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "255d1648e1114e5f8454cfb35f6cdd4d",
    "deepnote_cell_type": "markdown",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Implementation of integrand of the Cost Function\n",
    "Remember that the minimum-time objective can be written in integral form\n",
    "$$\\int_{0}^{\\infty} \\ell(\\mathbf{x}) dt,$$\n",
    "by defining\n",
    "$$\\ell(\\mathbf{x}) = \\begin{cases} 0 & \\text{if} \\quad \\mathbf{x} =0,\\\\ 1 & \\text{otherwise}. \\end{cases}$$\n",
    "(See also [the example from the textbook](https://underactuated.csail.mit.edu/dp.html#minimum_time_double_integrator).)\n",
    "Implement the integrand of cost function $$l(x)$$ using context as an argument.\n",
    "\n",
    "**Note**: To handle small numerical errors, the implementation of checking whether $$x=0$$ should be approximated using ```numpy``` function ```isclose``` instead of ```if x == 0```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "dd14d8b027d945668521effd5178a927",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1,
    "execution_start": 1676517257030,
    "pycharm": {
     "name": "#%%\n"
    },
    "source_hash": "f9cfac06",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cost_function(context):\n",
    "    # Modify here to get the correct state vector value from context.\n",
    "    # Hint: Once you get a BasicVector in Drake, then call CopyToVector() to get a\n",
    "    # numpy array.\n",
    "    x = np.array([0.0, 0.0])\n",
    "    return 0  # Modify here to compute the cost function"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "68402bdaf3824e02bde8755bb90e2018",
    "deepnote_cell_type": "markdown",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Value Iteration Algorithm\n",
    "The value iteration is implemented in the Drake function\n",
    "`FittedValueIteration`. Take some time to have a look at [its\n",
    "documentation](https://drake.mit.edu/doxygen_cxx/group__control.html#ga32d5768cb664f6d07fc58b4af536c45a),\n",
    "and to go through the description of this algorithm in [the\n",
    "textbook](https://underactuated.csail.mit.edu/dp.html#barycentric). Before\n",
    "using it, we need to construct an appropriate discretization of the state and\n",
    "input space.\n",
    "\n",
    "**Important:** This code will work if you change the limits of the input to be\n",
    "different from $u_{\\text{min}} = -1$ and $u_{\\text{max}} = 1$. However, be\n",
    "aware that the closed-form solution we derived in class (and that you'll have\n",
    "to implement at the end of this notebook) is assuming that! It's not hard to\n",
    "generalize the closed-form solution to the case with generic bounds\n",
    "$u_{\\text{min}}$ and $u_{\\text{max}}$. But if you don't want to do that, do not\n",
    "change `mesh['u_lim']` below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "68f843b09eeb477e92dfb696285886c6",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 0,
    "execution_start": 1676517257033,
    "pycharm": {
     "name": "#%%\n"
    },
    "source_hash": "40da75c"
   },
   "outputs": [],
   "source": [
    "# discretization mesh of state space, input space,\n",
    "# and time for the value-iteration algorithm\n",
    "mesh = {}\n",
    "\n",
    "# number of knot points in the grids\n",
    "# odd to have a point in the origin\n",
    "mesh[\"n_q\"] = 31  # do not exceed ~51/101\n",
    "mesh[\"n_qdot\"] = 31  # do not exceed ~51/101\n",
    "mesh[\"n_u\"] = 11  # don't exceed ~11/21\n",
    "\n",
    "# grid limits\n",
    "mesh[\"q_lim\"] = [-2.0, 2.0]\n",
    "mesh[\"qdot_lim\"] = [-2.0, 2.0]\n",
    "mesh[\"u_lim\"] = [-1.0, 1.0]  # do not change\n",
    "\n",
    "# axis discretization\n",
    "for s in [\"q\", \"qdot\", \"u\"]:\n",
    "    mesh[f\"{s}_grid\"] = np.linspace(*mesh[f\"{s}_lim\"], mesh[f\"n_{s}\"])\n",
    "\n",
    "    # important: ensure that a knot point is in the origin\n",
    "    # otherwise there is no way the value iteration can converge\n",
    "    assert 0.0 in mesh[f\"{s}_grid\"]\n",
    "\n",
    "# time discretization in the value-iteration algorithm\n",
    "mesh[\"timestep\"] = 0.005"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "dd11504121c4431bb31ba2c51c7e322c",
    "deepnote_cell_type": "markdown",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In the following cell we wrap Drake's `FittedValueIteration` function with a function we call `run_value_iteration`.\n",
    "This returns the optimal value function, the optimal controller, and all the data we need for the upcoming animation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "81207852406843e3b01b47cffbaf8541",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 4,
    "execution_start": 1676517257034,
    "pycharm": {
     "name": "#%%\n"
    },
    "source_hash": "d0f5e75f"
   },
   "outputs": [],
   "source": [
    "def run_value_iteration(cost_function, mesh, max_iter=10000):\n",
    "    # to create an animation, we store the values of\n",
    "    # the cost to go and the optimal policy for each\n",
    "    # iteration of the value-iteration algorithm\n",
    "    J_grid = []\n",
    "    pi_grid = []\n",
    "\n",
    "    # callback from the value-iteration algorithm\n",
    "    # that saves the intermediate values of J and pi\n",
    "    # and that ensures we do not exceed max_iter\n",
    "    # (iteration number i starts from 1)\n",
    "    def callback(i, unused, J, pi):\n",
    "        # check max iter is not exceeded\n",
    "        if i > max_iter:\n",
    "            raise RuntimeError(\n",
    "                f\"Value-iteration algorithm did not converge within {max_iter} iterations.\"\n",
    "            )\n",
    "\n",
    "        # store cost to go for iteration i\n",
    "        # the 'F' order facilitates the plot phase\n",
    "        J_grid.append(np.reshape(J, (mesh[\"n_q\"], mesh[\"n_qdot\"]), order=\"F\"))\n",
    "        pi_grid.append(np.reshape(pi, (mesh[\"n_q\"], mesh[\"n_qdot\"]), order=\"F\"))\n",
    "\n",
    "    # set up a simulation\n",
    "    simulator = Simulator(get_double_integrator())\n",
    "\n",
    "    # grids for the value-iteration algorithm\n",
    "    state_grid = [set(mesh[\"q_grid\"]), set(mesh[\"qdot_grid\"])]\n",
    "    input_grid = [set(mesh[\"u_grid\"])]\n",
    "\n",
    "    # add custom callback function as a visualization_callback\n",
    "    options = DynamicProgrammingOptions()\n",
    "    options.visualization_callback = callback\n",
    "\n",
    "    # run value-iteration algorithm\n",
    "    policy, cost_to_go = FittedValueIteration(\n",
    "        simulator,\n",
    "        cost_function,\n",
    "        state_grid,\n",
    "        input_grid,\n",
    "        mesh[\"timestep\"],\n",
    "        options,\n",
    "    )\n",
    "\n",
    "    # recast J and pi from lists to 3d arrays\n",
    "    J_grid = np.dstack(J_grid)\n",
    "    pi_grid = np.dstack(pi_grid)\n",
    "\n",
    "    return policy, cost_to_go, J_grid, pi_grid"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "5883c186a07945dfbfdc33261fa77b29",
    "deepnote_cell_type": "markdown",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Animation of the Value-Iteration Algorithm\n",
    "The animation of the value-iteration is coded mainly using matplotlib. If you are interested, feel free to check support function `create_animation` provided in [`minimum_time_utils.py`](https://github.com/RussTedrake/underactuated/blob/master/underactuated/exercises/dp/minimum_time_utils.py).\n",
    "What it does can be summarized as follows:\n",
    "- runs value iteration,\n",
    "- initializes an empty 3D surface plot for the value function and the policy,\n",
    "- creates the function `update_surf` that when called updates the surface plots from the previous point,\n",
    "- creates a fancy animation by calling `update_surf` many times.\n",
    "\n",
    "This animation is built for the purpose of visualizing value-iteration, therefore, we include supporting functions in a separate file and hope you can appreciate the relevant final results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "551be7e283fa4c23a3e8a859aa1f774d",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 11928,
    "execution_start": 1676517257038,
    "pycharm": {
     "name": "#%%\n"
    },
    "source_hash": "e609b59",
    "tags": []
   },
   "outputs": [],
   "source": [
    "policy, cost_to_go, J_grid, pi_grid = run_value_iteration(cost_function, mesh)\n",
    "animation = create_animation(J_grid, pi_grid, mesh)\n",
    "HTML(animation.to_jshtml())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "34c76a31d69b4904b70bf3a94ebaebe8",
    "deepnote_cell_type": "markdown",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Performance of the Value-Iteration Policy\n",
    "Value iteration is an extremely powerful and very general algorithm.\n",
    "However, its performances in solving \"bang-bang\" problems (i.e. problems where the control is always at the bounds) can be very poor.\n",
    "In this section we simulate the double integrator in closed-loop with the approximated optimal policy.\n",
    "We'll see that things do not go exactly how we expect..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "548bd620429349809342578f43ce460a",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 19206916,
    "execution_start": 1676517269661,
    "pycharm": {
     "name": "#%%\n"
    },
    "source_hash": "552e66a9"
   },
   "outputs": [],
   "source": [
    "# function that simulates the double integrator\n",
    "# starting from the state (q0, qdot0) for sim_time\n",
    "# seconds in closed loop with the passed controller\n",
    "\n",
    "\n",
    "def simulate(q0, qdot0, sim_time, controller):\n",
    "    # initialize block diagram\n",
    "    builder = DiagramBuilder()\n",
    "\n",
    "    # add system and controller\n",
    "    double_integrator = builder.AddSystem(get_double_integrator())\n",
    "    controller = builder.AddSystem(controller)\n",
    "\n",
    "    # wirw system and controller\n",
    "    builder.Connect(double_integrator.get_output_port(0), controller.get_input_port(0))\n",
    "    builder.Connect(controller.get_output_port(0), double_integrator.get_input_port(0))\n",
    "\n",
    "    # measure double-integrator state and input\n",
    "    state_logger = LogVectorOutput(double_integrator.get_output_port(0), builder)\n",
    "    input_logger = LogVectorOutput(controller.get_output_port(0), builder)\n",
    "\n",
    "    # finalize block diagram\n",
    "    diagram = builder.Build()\n",
    "\n",
    "    # instantiate simulator\n",
    "    simulator = Simulator(diagram)\n",
    "\n",
    "    # set initial conditions\n",
    "    context = simulator.get_mutable_context()\n",
    "    context.SetContinuousState([q0, qdot0])\n",
    "\n",
    "    # run simulation\n",
    "    simulator.AdvanceTo(sim_time)\n",
    "\n",
    "    # unpack sim results\n",
    "    q_sim, qdot_sim = state_logger.FindLog(context).data()\n",
    "    u_sim = input_logger.FindLog(context).data().flatten()\n",
    "    t_sim = state_logger.FindLog(context).sample_times()\n",
    "\n",
    "    return q_sim, qdot_sim, u_sim, t_sim"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "2b523a55a5e94b479b4e5cfd89a05327",
    "deepnote_cell_type": "markdown",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In order to properly visualize the results of the simulator above we need a bunch of helper functions. Since they are not directly relevant to drake simulation or value iteration algorithm, we included them in [`minimum_time_utils.py`](underactuated/exercises/dp/minimum_time_utils.py). Feel free to check the detailed implementation if you are interested."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "445187f4bb074185bd12ea29d9b3f8c9",
    "deepnote_cell_type": "markdown",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We are finally ready to simulate and plot the trajectories of the double integrator controlled by the value-iteration policy.\n",
    "Running the following cell you'll see two plots:\n",
    "- The plot of the state-space trajectory of the double integrator superimposed to the level plot of the policy.\n",
    "In the red regions the controller selects the input $u=1$ (full gas), in the blue regions it selects $u=-1$ (full brake). The are in between approximates the quadratic boundaries we have seen in class, and are due to the discretization of the state space.\n",
    "- The plot of the control force as a function of time.\n",
    "\n",
    "Is this the optimal policy we expected to see?\n",
    "Take your time to understand why these plots look so strange!\n",
    "Does this get any better if you increase the number of knot points (finer discretization of $q$ and $\\dot{q}$)?\n",
    "If no, why?\n",
    "(Questions not graded, do not submit.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "5771b7fa2e8a4bf9996799ec153b2033",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1813,
    "execution_start": 1676517269664,
    "pycharm": {
     "name": "#%%\n"
    },
    "source_hash": "c612ede8"
   },
   "outputs": [],
   "source": [
    "# initial state\n",
    "q0 = -1.0\n",
    "qdot0 = 0.0\n",
    "\n",
    "# verify that the given initial state is inside the value-iteration grid\n",
    "assert mesh[\"q_lim\"][0] <= q0 <= mesh[\"q_lim\"][1]\n",
    "assert mesh[\"qdot_lim\"][0] <= qdot0 <= mesh[\"qdot_lim\"][1]\n",
    "\n",
    "# duration of the simulation in seconds\n",
    "sim_time = 5.0\n",
    "\n",
    "# sim and plot\n",
    "policy = run_value_iteration(cost_function, mesh)[0]\n",
    "simulate_and_plot(q0, qdot0, sim_time, policy, mesh[\"u_lim\"], simulate=simulate)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "676d1b96ba4542b0ac67eb88009f4e45",
    "deepnote_cell_type": "markdown",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Implementation of the Closed-Form Solution\n",
    "Since value iteration didn't give us the results we wanted, in the next cell we ask you to implement [the closed-form solution we've derived in class](https://underactuated.csail.mit.edu/dp.html#minimum_time_double_integrator).\n",
    "Note that in class we assumed the input to be bounded between $-1$ and $1$, so you can either do the math and generalize that result to generic bounds $u_{\\text{min}} < 0$ and $u_{\\text{max}} > 0$ (not hard), or double check that `mesh['u_lim']` is still set to `[-1., 1.]`.\n",
    "\n",
    "**Note 1:**\n",
    "To help you, we already partially filled the function.\n",
    "In a small neighborhood of the origin we return $u = - \\dot{q} - q$, even if the theoretical solution would say $u = 0$.\n",
    "This gives the closed-loop dynamics $m \\ddot{q} = - q - \\dot{q}$ which makes the origin a stable equilibrium.\n",
    "This trick prevents the controller from chattering wildly between $u_{\\text{max}}$ and $u_{\\text{min}}$ because of small numerical errors.\n",
    "Do not cancel it.\n",
    "\n",
    "**Note 2:**\n",
    "To complete this function with [the control law from the textbook](https://underactuated.csail.mit.edu/dp.html#minimum_time_double_integrator)\n",
    "you need to write two conditions on the state $[q, \\dot{q}]^T$: one for the full-gas region and one for the full-brake region.\n",
    "Notice that, momentarily, the function always returns $u = u_{\\text{max}}$ if the state is not close to the origin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "aa26290a547c48569f7228c4064a9672",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 4,
    "execution_start": 1676517271475,
    "pycharm": {
     "name": "#%%\n"
    },
    "source_hash": "4c55d5bd"
   },
   "outputs": [],
   "source": [
    "def policy_closed_form(q, qdot, atol=1.0e-2):\n",
    "    # system in a neighborhood of the origin\n",
    "    # up to the absolute tolerance atol\n",
    "    x_norm = np.linalg.norm([q, qdot])\n",
    "    if np.isclose(x_norm, 0.0, atol=atol):\n",
    "        # little trick, do not modify: use a stabilizing controller in the\n",
    "        # neighborhood of the origin to prevent wild chattering\n",
    "        return -q - qdot\n",
    "\n",
    "    # full-brake region\n",
    "    # check if the state of the system is\n",
    "    # such that u must be set to -1\n",
    "    elif False:  # modify here\n",
    "        return mesh[\"u_lim\"][0]\n",
    "\n",
    "    # full-gas region\n",
    "    # if all the others do not apply,\n",
    "    # u must be set to 1\n",
    "    else:  # modify here\n",
    "        return mesh[\"u_lim\"][1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "fc6d9b09be9049eb9d8076621010017b",
    "deepnote_cell_type": "markdown",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now we just encapsulate the function you wrote in a Drake `LeafSystem` that can be sent to the simulator.\n",
    "Does this state trajectory and this control signal look more reasonable than the ones from the value-iteration algorithm? (Question not graded, do not submit.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "a5480160ddff40398e83ed7dbfb7f4f0",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 3672,
    "execution_start": 1676517271501,
    "pycharm": {
     "name": "#%%\n"
    },
    "source_hash": "ccdd00cd"
   },
   "outputs": [],
   "source": [
    "# controller which implements the closed-form solution\n",
    "\n",
    "\n",
    "class ClosedFormController(LeafSystem):\n",
    "    # two inputs (system state)\n",
    "    # one output (system input)\n",
    "    def __init__(self):\n",
    "        LeafSystem.__init__(self)\n",
    "        self.DeclareVectorInputPort(\"x\", 2)\n",
    "        self.DeclareVectorOutputPort(\"u\", 1, self.DoCalcVectorOutput)\n",
    "\n",
    "    # just evaluate the function above\n",
    "    def DoCalcVectorOutput(self, context, u):\n",
    "        x = self.get_input_port(0).Eval(context)\n",
    "        u.SetAtIndex(0, policy_closed_form(*x))\n",
    "\n",
    "\n",
    "# sim and plot\n",
    "simulate_and_plot(\n",
    "    q0,\n",
    "    qdot0,\n",
    "    sim_time,\n",
    "    ClosedFormController(),\n",
    "    mesh[\"u_lim\"],\n",
    "    simulate=simulate,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "4395e64402604555882cdfa755bcc6a7",
    "deepnote_cell_type": "markdown",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Autograding\n",
    "You can check your work by running the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "aa7669fab275461895cd9f8c08d4aede",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 587,
    "execution_start": 1676517275172,
    "pycharm": {
     "name": "#%%\n"
    },
    "source_hash": "57d0c95b"
   },
   "outputs": [],
   "source": [
    "from underactuated.exercises.dp.test_minimum_time import TestMinimumTime\n",
    "from underactuated.exercises.grader import Grader\n",
    "\n",
    "Grader.grade_output([TestMinimumTime], [locals()], \"results.json\")\n",
    "Grader.print_test_results(\"results.json\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=5d164217-c09d-4ecb-b19c-a1b65e9cf513' target=\"_blank\">\n",
    "<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n",
    "Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "592b6fb623234cc4b57d0917aecc60f0",
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
